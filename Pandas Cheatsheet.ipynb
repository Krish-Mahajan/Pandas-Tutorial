{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **To read csv File**    \n",
    "pmpm=pd.read_csv('../pmpm.csv',dtype{'new_euid':'str','imp_prov_npi':'str')  \n",
    "\n",
    "\n",
    "- **To subset columns of a dataframe**   \n",
    "pmpm=pd.read_csv('../pmpm.csv',dtype{'new_euid':'str','imp_prov_npi':'str'})  \n",
    "\n",
    "\n",
    "- **To check basic stats**     \n",
    "df.info()  \n",
    "df.describe()    \n",
    "\n",
    "\n",
    "\n",
    "- **To check dtypes of columns**      \n",
    "df.dtypes    \n",
    "\n",
    "\n",
    "\n",
    "- **To check first few rows**    \n",
    "df.head()    \n",
    "\n",
    "\n",
    "- ** To check Distinct values in a column **  \n",
    "count_nl.count_label.unique()    \n",
    "\n",
    "\n",
    "- **To check dimensions of the dataframe**  \n",
    "df.shape    \n",
    "\n",
    "\n",
    "- **To check unique() values in a column**     \n",
    "len(hedis_euid['new_euid'].unique())  \n",
    "\n",
    "-  ** To Transpose **  \n",
    "df=df.transpose()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection Operations  & Indexing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **To select rows based on some conditions**  \n",
    "nl[nl.Id=='1477506657']   \n",
    "df_with_Label_pivoted_subset=df_with_Label_pivoted[df_with_Label_pivoted['Label'].isin([11.0,18.0,38.0,118.0,32.0])]  \n",
    "\n",
    "\n",
    "- **To update rows based on some conditions**  \n",
    "nl_hedis_imputedComm.loc[nl_hedis_imputedComm.NUMR_CNT>1,'NUMR_CNT']=1 \n",
    "#converting 'NUMR_CNT' greater than 1 number_CNT has 1    \n",
    "\n",
    "\n",
    "- **Column Selection**  \n",
    "df.ix[:,0:len(df.columns)-1] #select first n-1 column  \n",
    "\n",
    "\n",
    "- **Adding columns**  \n",
    "df_with_Label_pivoted['Total']=df_with_Label_pivoted.ix[:,3] + df_with_Label_pivoted.ix[:,4]     \n",
    "pmpm_diabetic_ddup['ID']=pmpm_diabetic_ddup.index.map(str)+\"-(\"+pmpm_diabetic_ddup.Total.map(str)+\")\"\n",
    "\n",
    "\n",
    "-  **Reset Index**    \n",
    "df_with_Label=with_Label.reset_index() \n",
    "df_with_Label_pivoted.reset_index(inplace=True) \n",
    "\n",
    "\n",
    "- **To Assign columns name from rows**    \n",
    "df.columns=df.iloc[0]   \n",
    "\n",
    "\n",
    "- **Dropping Columns**  \n",
    "df.drop('column_name',axis=1,inplace=True)    \n",
    "del df['column']\n",
    "\n",
    "\n",
    "- ** Renaming 0 column **  \n",
    "diabetic_agg=diabetic_agg.rename(columns = {0:'Total'})    \n",
    "\n",
    "\n",
    "- ** Renaming Index **   \n",
    "codes_stats.index.rename('NAME',inplace=True)    \n",
    "\n",
    "\n",
    "- **Removing 0 columns**  \n",
    "pmpm_diabetic=pmpm_diabetic.loc[:,(pmpm_diabetic!=0).any(axis=0)] #removing 0 columns  \n",
    "\n",
    "\n",
    "\n",
    "- **Removing 0 rows**  \n",
    "pmpm_diabetic=pmpm_diabetic[(pmpm_diabetic.T!=0).any()]   \n",
    "\n",
    "\n",
    "- **Drop Columns based on column sum**  \n",
    "pmpm_diabetic=pmpm_diabetic.loc[:,(pmpm_diabetic.sum()>=50)]   \n",
    "\n",
    "\n",
    "- **Concat Two DataFrame on column axis**  \n",
    "df_new=pd.concat([df1.reset_index(),df2], axis=1)   \n",
    "\n",
    "\n",
    "- **Changing Position of columns**  \n",
    "cols = df.columns.tolist()  \n",
    "cols = cols[-1:] + cols[:-1] \n",
    "df = df[cols]  \n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group By Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Group_by by length of a column  **    \n",
    "imputedComm.groupby(imputedComm['new_euid'].str.len()).agg({'new_euid':np.size})   \n",
    "\n",
    "\n",
    "-  ** Groub_by and founf count_distinct and sort**    \n",
    "count_nl=nl.groupby(nl['Id']).Label.nunique().sort_values(ascending=False)    \n",
    "\n",
    "\n",
    "\n",
    "-  ** Group by categorical variable to count **    \n",
    "count_nl=count_nl.groupby(count_nl.count_label).size()    \n",
    "nl_hedis_imputedComm.meas_submeas_id.value_counts()        \n",
    "\n",
    "\n",
    "\n",
    "- **To group by and count nuinque users**     \n",
    "with_Label=nl_hedis_imputedComm\n",
    ".groupby(['Label','meas_submeas_id','INVERT_MEAS_FLG','NUMR_CNT'])\n",
    ".new_euid.nunique()       \n",
    "\n",
    "\n",
    "- ** To Group by and count distinct **     \n",
    " df_x=df.groupby(['meas_submeas_id']).agg({'Label':pd.Series.nunique,'new_euid':np.size})   \n",
    " \n",
    " \n",
    " \n",
    "- ** Deduplicate Data **  \n",
    "diabetic_agg=pd.DataFrame(df.groupby(df.columns.tolist(),as_index=False).size()) \n",
    " \n",
    " \n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Remove leading zeros of a column**  \n",
    "imputedComm['new_euid'] = imputedComm['new_euid'].map(lambda x: str(x).lstrip('0'))    \n",
    "x['no_of_communites'] = x[\"Measures\"].map(lambda x:len(x))  \n",
    "\n",
    "\n",
    "\n",
    "- **To count column wise NULL values**  \n",
    "hedis_imputedComm.isnull().sum()    \n",
    "\n",
    "\n",
    "- **Fill na values**\n",
    "df=df.fillna(0)    \n",
    "\n",
    "\n",
    "\n",
    "- ** All non zero rows of a DataFrame ** \n",
    "df[(df.T!=0).any()].shape   ### non zero vector  \n",
    "df[(df.T==0).all()].shape   ### Zero row  \n",
    "\n",
    "\n",
    "\n",
    "- ** count NAN values numpy array **  \n",
    "np.isnan(data_dist).sum() \n",
    "np.count_nonzero(np.isnan(data_dist))   \n",
    "\n",
    "\n",
    "- ** Removing NAN Values numpy array ** \n",
    "data_dist=data_dist[~np.isnan(data_dist)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging and Operating from other Datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** To Make dataframes from series **  \n",
    "count_nl=pd.DataFrame({'Id':count_nl.index,'count_label':count_nl.values})   \n",
    "\n",
    "\n",
    "- ** To make dataFrame from Dictionary ** \n",
    "x=pd.DataFrame(communities.items(),columns=['Label','Measures'])  \n",
    "\n",
    "\n",
    "\n",
    "- ** To merge two dataframes **  \n",
    "nl_hedis_imputedComm=pd.merge(nl,hedis_imputedComm,left_on=\"Id\",right_on='imp_prov_npi', how=\"inner\")   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-  ** Reading from Dictionary and filling dataframe line by line**   \n",
    "\n",
    "df=pd.DataFrame(columns=['Id','Label'])\n",
    "for key,value in nl_new.iteritems(): \n",
    "    for npi in key:\n",
    "        x= pd.DataFrame(index=range(1,2),columns=(['Id','Label']))\n",
    "        x.ix[:,0] = npi\n",
    "        x.ix[:,1] = nl_new[key]\n",
    "        #print(x)\n",
    "        df=df.append(x)\n",
    "        #print(df)  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivoting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  **Pivot Table**  \n",
    "df_with_Label_pivoted= df_with_Label.pivot_table(\n",
    "index=['Label','meas_submeas_id','INVERT_MEAS_FLG'],\n",
    "columns=['NUMR_CNT'],values='new_euid')      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Sort DataBase based on coulmn values**  \n",
    "df_without_Label_pivoted.sort(['Total'],ascending=False,inplace=True) #sorting based on Total column   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Hierarchical Clustering **  \n",
    "    data_dist =pdist(df,'jaccard') \n",
    "    data_link=linkage(data_dist)\n",
    "    dendrogram(data_link,labels=df.index,leaf_rotation=90.,leaf_font_size=8.)\n",
    "    plt.xlabel('CHCC_G Codes')\n",
    "    plt.ylabel('Jaccard Distance')\n",
    "    plt.suptitle('Disease Clustering(CHCC_G Codes)', fontweight='bold')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tips & Tricks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **To suppress scientific notation**  \n",
    "np.set_printoptions(precision=5, suppress=True)   \n",
    "\n",
    "- **To increase Maximum recursion Depth \n",
    "import sys \n",
    "sys.setrecursionlimit(10000)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
