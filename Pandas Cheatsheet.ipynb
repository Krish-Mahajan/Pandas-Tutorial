{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **To read csv File**    \n",
    "pmpm=pd.read_csv('../pmpm.csv',dtype{'new_euid':'str','imp_prov_npi':'str')  \n",
    "\n",
    "\n",
    "- **To subset columns of a dataframe**   \n",
    "pmpm=pd.read_csv('../pmpm.csv',dtype{'new_euid':'str','imp_prov_npi':'str'})  \n",
    "\n",
    "\n",
    "- **To check basic stats**     \n",
    "df.info()  \n",
    "df.describe()    \n",
    "\n",
    "\n",
    "\n",
    "- **To check dtypes of columns**      \n",
    "df.dtypes    \n",
    "\n",
    "\n",
    "\n",
    "- **To check first few rows**    \n",
    "df.head()    \n",
    "\n",
    "\n",
    "- ** To check Distinct values in a column **  \n",
    "count_nl.count_label.unique()    \n",
    "\n",
    "\n",
    "- **To check dimensions of the dataframe**  \n",
    "df.shape      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **To check unique() values in a column**     \n",
    "len(hedis_euid['new_euid'].unique())    \n",
    "\n",
    "\n",
    "\n",
    "-  ** To Transpose **  \n",
    "df=df.transpose()     \n",
    "\n",
    "\n",
    "- ** To define a DataFrame with index of another DataFrame **  \n",
    "df_new=pd.DataFrame(columns=cols,index=df_old.index)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection Operations  & Indexing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **To select rows based on some conditions**  \n",
    "df[df.col1=='xxxx']   \n",
    "df=df[df['col'].isin([list elements])]  \n",
    "\n",
    "\n",
    "- **To update rows based on some conditions**  \n",
    "df.loc[df.col1>1,'col1']=1  #converting 'col1' greater than 1 number_CNT has 1    \n",
    "\n",
    "\n",
    "- **Column Selection**  \n",
    "df.ix[:,0:len(df.columns)-1] #select first n-1 columns  \n",
    "\n",
    "\n",
    "- **Adding columns**  \n",
    "df['col_new']=df.ix[:,3] + df.ix[:,4]     #Adding column with column position\n",
    "df['col_new']=df.index.map(str)+ \"-(\"+ df.column.map(str)+\")\" #Adding column with name\n",
    "\n",
    "\n",
    "-  **Reset Index**    \n",
    "df_new=df_old.reset_index() \n",
    "df.reset_index(inplace=True) \n",
    "\n",
    "\n",
    "- **Add null column**  \n",
    "df['col']=np.nan\n",
    "\n",
    "- **To Assign columns name from rows**    \n",
    "df.columns=df.iloc[0]   \n",
    "\n",
    "\n",
    "- **Dropping Columns**  \n",
    "df.drop('column_name',axis=1,inplace=True)    \n",
    "del df['column']\n",
    "\n",
    "\n",
    "- ** Renaming 0 column **  \n",
    "df=df.rename(columns = {0:'Total'})    \n",
    "\n",
    "\n",
    "- ** Renaming Index **   \n",
    "df.index.rename('col1',inplace=True)    \n",
    "\n",
    "\n",
    "- ** Removing 0 columns **  \n",
    "df=df.loc[:,(df!=0).any(axis=0)] #removing 0 columns  \n",
    "\n",
    "\n",
    "\n",
    "- **Removing 0 rows**  \n",
    "df=df[(df.T!=0).any()]   \n",
    "\n",
    "\n",
    "- **Drop Columns based on column sum**  \n",
    "df=df.loc[:,(df.sum()>=50)]   \n",
    "\n",
    "\n",
    "- **Concat Two DataFrame on column axis**  \n",
    "df_new=pd.concat([df1.reset_index(),df2], axis=1)   \n",
    "\n",
    "\n",
    "- **Changing Position of columns**  \n",
    "cols = df.columns.tolist()  \n",
    "cols = cols[-1:] + cols[:-1] \n",
    "df = df[cols]    \n",
    "\n",
    "\n",
    "\n",
    "- ** Change Data Types multiple columns**  \n",
    "cols=['col1','col2','col3','col4']\n",
    "all_diabetic[cols] = all_diabetic[cols].astype(int)   \n",
    "df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)  \n",
    "\n",
    "\n",
    "- ** To apply function over each cell**  \n",
    "df_old=df.applymap(f1)  \n",
    "\n",
    "\n",
    "- ** To slice dataframe using column name**  \n",
    "df_new=df.ix[:,'col1':'col2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group By Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Group_by by length of a column  **    \n",
    "df.groupby(df['new_euid'].str.len()).agg({'new_euid':np.size})   \n",
    "\n",
    "\n",
    "-  ** Groub_by and founf count_distinct and sort**    \n",
    "count_nl=nl.groupby(nl['Id']).Label.nunique().sort_values(ascending=False)    \n",
    "\n",
    "\n",
    "\n",
    "-  ** Group by categorical variable to count **    \n",
    "count_nl=count_nl.groupby(count_nl.count_label).size()    \n",
    "nl_hedis_imputedComm.meas_submeas_id.value_counts()        \n",
    "\n",
    "\n",
    "\n",
    "- **To group by and count nuinque users**     \n",
    "with_Label=nl_hedis_imputedComm\n",
    ".groupby(['Label','meas_submeas_id','INVERT_MEAS_FLG','NUMR_CNT'])\n",
    ".new_euid.nunique()       \n",
    "\n",
    "\n",
    "- ** To Group by and count distinct **     \n",
    " df_x=df.groupby(['meas_submeas_id']).agg({'Label':pd.Series.nunique,'new_euid':np.size})   \n",
    " \n",
    " \n",
    " \n",
    "- ** Deduplicate Data **  \n",
    "df=pd.DataFrame(df.groupby(df.columns.tolist(),as_index=False).size())  \n",
    "\n",
    "\n",
    "\n",
    " - ** To Group by some variable and some all other variable**\n",
    "df_new=df_old.groupby(check['col1']).sum()\n",
    " \n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Remove leading zeros of a column**  \n",
    "df['col'] = df['col'].map(lambda x: str(x).lstrip('0'))    \n",
    "df['col_new'] = df[\"col_new\"].map(lambda x:len(x))  \n",
    "\n",
    "\n",
    "\n",
    "- **To count column wise NULL values**  \n",
    "hedis_imputedComm.isnull().sum()    \n",
    "\n",
    "\n",
    "- **Fill na values**  \n",
    "df=df.fillna(0)    \n",
    "\n",
    "\n",
    "\n",
    "- ** All non zero rows of a DataFrame **   \n",
    "df[(df.T!=0).any()].shape   ### non zero vector  \n",
    "df[(df.T==0).all()].shape   ### Zero row  \n",
    "\n",
    "\n",
    "\n",
    "- ** count NAN values numpy array **  \n",
    "np.isnan(data_dist).sum() \n",
    "np.count_nonzero(np.isnan(data_dist))   \n",
    "\n",
    "\n",
    "- ** Removing NAN Values numpy array **   \n",
    "data_dist=data_dist[~np.isnan(data_dist)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging and Operating from other Datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** To Make dataframes from series **  \n",
    "count_nl=pd.DataFrame({'Id':count_nl.index,'count_label':count_nl.values})   \n",
    "\n",
    "\n",
    "- ** To make dataFrame from Dictionary ** \n",
    "x=pd.DataFrame(communities.items(),columns=['Label','Measures'])  \n",
    "\n",
    "\n",
    "\n",
    "- ** To merge two dataframes **  \n",
    "nl_hedis_imputedComm=pd.merge(nl,hedis_imputedComm,left_on=\"Id\",right_on='imp_prov_npi', how=\"inner\")   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-  ** Reading from Dictionary and filling new dataframe line by line**   \n",
    "df=pd.DataFrame(columns=['Id','Label'])\n",
    "for key,value in nl_new.iteritems(): \n",
    "    for npi in key:\n",
    "        x= pd.DataFrame(index=range(1,2),columns=(['Id','Label']))\n",
    "        x.ix[:,0] = npi\n",
    "        x.ix[:,1] = nl_new[key]\n",
    "        #print(x)\n",
    "        df=df.append(x)\n",
    "        #print(df)     \n",
    "        \n",
    "        \n",
    " \n",
    " - ** To efficiently interate through rows of a DataFrame  **  \n",
    "  for index,row in df.iterrows():   \n",
    "      row['col1'],row['col2']  \n",
    "      df.loc[index/condition,'col_new]=some_value\n",
    "-       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivoting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  **Pivot Table**  \n",
    "df_with_Label_pivoted= df_with_Label.pivot_table(\n",
    "index=['Label','meas_submeas_id','INVERT_MEAS_FLG'],\n",
    "columns=['NUMR_CNT'],values='new_euid')      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Sort DataBase based on coulmn values**  \n",
    "df.sort(['col'],ascending=False,inplace=True) #sorting based on Total column   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Hierarchical Clustering **  \n",
    "    data_dist =pdist(df,'jaccard') \n",
    "    data_link=linkage(data_dist)\n",
    "    dendrogram(data_link,labels=df.index,leaf_rotation=90.,leaf_font_size=8.)\n",
    "    plt.xlabel('CHCC_G Codes')\n",
    "    plt.ylabel('Jaccard Distance')\n",
    "    plt.suptitle('Disease Clustering(CHCC_G Codes)', fontweight='bold')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tips & Tricks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **To suppress scientific notation**  \n",
    "np.set_printoptions(precision=5, suppress=True)  \n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "- **To increase Maximum recursion Depth**   \n",
    "import sys   \n",
    "sys.setrecursionlimit(10000)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
