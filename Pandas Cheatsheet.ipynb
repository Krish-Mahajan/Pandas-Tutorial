{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **To read csv File**    \n",
    "df=pd.read_csv('filename.csv',dtype{'col1':'type1','col2':'type2'},usecols=['col1',col2'])  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **To check basic stats**     \n",
    "df.info()  \n",
    "df.describe()    \n",
    "\n",
    "\n",
    "\n",
    "- **To check dtypes of columns**      \n",
    "df.dtypes    \n",
    "\n",
    "\n",
    "\n",
    "- **To check first few rows**    \n",
    "df.head()    \n",
    "\n",
    "\n",
    "- ** To check Distinct values in a column **  \n",
    "df.column.unique()    \n",
    "\n",
    "\n",
    "- **To check dimensions of the dataframe**  \n",
    "df.shape      \n",
    "\n",
    "\n",
    "- ** Changing Datatypes of columns **  \n",
    "cols=df.columns.tolist()\n",
    "df[cols]=df[cols].astype('type')\n",
    "\n",
    "\n",
    "\n",
    "- **To check unique() values in a column**     \n",
    "len(df['col'].unique())    \n",
    "\n",
    "\n",
    "\n",
    "-  ** To Transpose **  \n",
    "df=df.transpose()     \n",
    "\n",
    "\n",
    "- ** To define a DataFrame with index of another DataFrame **  \n",
    "df_new=pd.DataFrame(columns=cols,index=df_old.index)    \n",
    "\n",
    "\n",
    "- ** Round all cells of DataFrame ** \n",
    "df=df.round(1)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection Operations  & Indexing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **To select rows based on some conditions**  \n",
    "df[df.col1=='xxxx']   \n",
    "df=df[df['col'].isin([list elements])]  \n",
    "\n",
    "\n",
    "- **To update rows based on some conditions**  \n",
    "df.loc[df.col1>1,'col1']=1  #converting 'col1' greater than 1 to 1    \n",
    "\n",
    "\n",
    "- **Column Selection**  \n",
    "df.ix[:,0:len(df.columns)-1] #select first n-1 columns  \n",
    "\n",
    "\n",
    "- **Adding columns**  \n",
    ">> df['col_new']=df.ix[:,3] + df.ix[:,4]     #Adding column with column position    \n",
    "\n",
    ">> df['col_new']=df.index.map(str)+ \"-(\"+ df.column.map(str)+\")\" #Adding column with name  \n",
    "\n",
    ">> df.insert(loc,'col',value(np.nan))  \n",
    "\n",
    ">> df['col']=np.nan  #Adding Null column  \n",
    "\n",
    "\n",
    "-  **Reset Index**    \n",
    "df_new=df_old.reset_index() \n",
    "df.reset_index(inplace=True)   \n",
    "\n",
    "\n",
    "- **To Assign columns name from first row**    \n",
    "df.columns=df.iloc[0]   \n",
    "\n",
    "\n",
    "- **Dropping Columns**   \n",
    "\n",
    ">>df.drop('column_name',axis=1,inplace=True)  \n",
    "\n",
    ">>del df['column']  \n",
    "\n",
    ">>df.drop(['col1'...'colx'],axis=1,inplace=True) \n",
    "\n",
    "\n",
    ">>**Drop Columns based on column sum**  \n",
    "df=df.loc[:,(df.sum()>=50)]    \n",
    "\n",
    ">> ** Removing 0 columns **    \n",
    "df=df.loc[:,(df!=0).any(axis=0)] #removing 0 columns  \n",
    "\n",
    "\n",
    "\n",
    "- ** Renaming 0 column **  \n",
    "df=df.rename(columns = {0:'Total'})    \n",
    "\n",
    "\n",
    "- ** Renaming Index **   \n",
    "df.index.rename('col1',inplace=True)    \n",
    "\n",
    "\n",
    "\n",
    "- **Removing 0 rows**  \n",
    "df=df[(df.T!=0).any()]   \n",
    "\n",
    "\n",
    "- **Changing Position of columns**  \n",
    "cols = df.columns.tolist()  \n",
    "cols = cols[-1:] + cols[:-1] \n",
    "df = df[cols]   \n",
    "  \n",
    "\n",
    "\n",
    "- **Concat Two DataFrame on column axis**  \n",
    "df_new=pd.concat([df1.reset_index(),df2], axis=1)   \n",
    "\n",
    "\n",
    " - ** Change Data Types multiple columns**  \n",
    "cols=['col1','col2','col3','col4']\n",
    "all_diabetic[cols] = all_diabetic[cols].astype(int)   \n",
    "df[['col2','col3']] = df[['col2','col3']].apply(pd.to_numeric)  \n",
    "\n",
    "\n",
    "- ** To apply function over each cell**  \n",
    "df_old=df.applymap(f1)  \n",
    "\n",
    "\n",
    "- ** To slice dataframe using column name**  \n",
    "df_new=df.ix[:,'col1':'col2'].shape  \n",
    "\n",
    "\n",
    "- ** Summing across column ** \n",
    "comm_clust['Total_Patients']=comm_clust.sum(axis=1) \n",
    "\n",
    "\n",
    "- ** Summing across rows **  \n",
    "comm_clust.loc['Total']=comm_clust.sum()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **cleaning  column** \n",
    "\n",
    "    >>**Stripping front 0's from the column**       \n",
    "```df['col'] = df['col'].map(lambda x: str(x).lstrip('0'))```   \n",
    "\n",
    "    >>**Finding length of columns**  \n",
    "```df['col_new'] = df[\"col\"].map(lambda x:len(x))```     \n",
    "\n",
    "    >>**cleaning white-spaces**\n",
    "```df['col']=df['col'].map(lambda x:x.strip())```  \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group By Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Group_by by length of a column  **    \n",
    "df.groupby(df['col'].str.len()).agg({'col':np.size})   \n",
    "\n",
    "\n",
    "-  ** Groub_by and founf count_distinct and sort**    \n",
    "df_group=df.groupby(df[col]).col.nunique().sort_values(ascending=False)    \n",
    "\n",
    "\n",
    "\n",
    "-  ** Group by categorical variable to count **    \n",
    "df_group=df.groupby(df.col).size()    \n",
    "df.col.value_counts()    #without grouping.\n",
    "\n",
    "\n",
    "\n",
    "- **To group by and count nuinque users**     \n",
    "df_group=df.groupby(['col1','col2','col3','col4']).col.nunique()       \n",
    "\n",
    "\n",
    "- ** To Group by and count distinct **      \n",
    " df_x=df.groupby(['col']).agg({'col1':pd.Series.nunique,'col2':np.size})   \n",
    " \n",
    " \n",
    " \n",
    "- ** Deduplicate Data **  \n",
    "df=pd.DataFrame(df.groupby(df.columns.tolist(),as_index=False).size())  \n",
    "\n",
    "\n",
    " - ** To Group by some variable and some all other variable**\n",
    "df_new=df.groupby(df['col1']).sum()  \n",
    "\n",
    "\n",
    "- ** To group by some variable and take most frequent of other variable**  \n",
    "df[['svc_npi','svc_specialty']].groupby(['svc_npi']).agg(lambda x:stats.mode(x['svc_specialty'])[0])\n",
    "\n",
    " \n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>**To see rows where particular columns is null**  \n",
    "```df[df['col'].isnull()]```  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **To count column wise NULL values**  \n",
    "df.isnull().sum()    \n",
    "\n",
    "\n",
    "- **Fill na values**  \n",
    "df=df.fillna(0)    \n",
    "\n",
    "\n",
    "\n",
    "- ** All non zero rows of a DataFrame **   \n",
    "df[(df.T!=0).any()].shape   ### non zero vector  \n",
    "df[(df.T==0).all()].shape   ### Zero row  \n",
    "\n",
    "\n",
    "\n",
    "- ** count NAN values numpy array **  \n",
    "np.isnan(df).sum() \n",
    "np.count_nonzero(np.isnan(df))   \n",
    "\n",
    "\n",
    "- ** Removing NAN Values numpy array **   \n",
    "df=df[~np.isnan(data_dist)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging and Operating from other Datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** To Make dataframes from series **  \n",
    "count_nl=pd.DataFrame({'Id':count_nl.index,'count_label':count_nl.values})   \n",
    "\n",
    "\n",
    "- ** To make dataFrame from Dictionary ** \n",
    "x=pd.DataFrame(communities.items(),columns=['Label','Measures'])  \n",
    "\n",
    "\n",
    "\n",
    "- ** To merge two dataframes **  \n",
    "nl_hedis_imputedComm=pd.merge(nl,hedis_imputedComm,left_on=\"Id\",right_on='imp_prov_npi', how=\"inner\")   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-  ** Reading from Dictionary and filling new dataframe line by line**   \n",
    "df=pd.DataFrame(columns=['Id','Label'])\n",
    "for key,value in nl_new.iteritems(): \n",
    "    for npi in key:\n",
    "        x= pd.DataFrame(index=range(1,2),columns=(['Id','Label']))\n",
    "        x.ix[:,0] = npi\n",
    "        x.ix[:,1] = nl_new[key]\n",
    "        #print(x)\n",
    "        df=df.append(x)\n",
    "        #print(df)     \n",
    "        \n",
    "        \n",
    " \n",
    " - ** To efficiently interate through rows of a DataFrame  **  \n",
    "  for index,row in df.iterrows():   \n",
    "      row['col1'],row['col2']  \n",
    "      df.loc[index/condition,'col_new]=some_value\n",
    "-       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivoting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  **Pivot Table**    \n",
    "df_with_Label_pivoted= df_with_Label.pivot_table(index=['Label','meas_submeas_id','INVERT_MEAS_FLG'],columns=['NUMR_CNT'],values='new_euid')     \n",
    "\n",
    "euid_npi_cluster_grouped_pivot= euid_npi_cluster_grouped.pivot(index='comm_npi',columns='clusters_id',values='new_euid')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Sort DataBase based on coulmn values**  \n",
    "df.sort(['col'],ascending=False,inplace=True) #sorting based on Total column   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Hierarchical Clustering **  \n",
    "    data_dist =pdist(df,'jaccard')   \n",
    "    data_link=linkage(data_dist)  \n",
    "    dendrogram(data_link,labels=df.index,leaf_rotation=90.,leaf_font_size=8.)  \n",
    "    plt.xlabel('CHCC_G Codes')  \n",
    "    plt.ylabel('Jaccard Distance')  \n",
    "    plt.suptitle('Disease Clustering(CHCC_G Codes)', fontweight='bold')  \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tips & Tricks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **To suppress scientific notation**  \n",
    "np.set_printoptions(precision=5, suppress=True)  \n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "- **To increase Maximum recursion Depth**   \n",
    "import sys   \n",
    "sys.setrecursionlimit(10000)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
