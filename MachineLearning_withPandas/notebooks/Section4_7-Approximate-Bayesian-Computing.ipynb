{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width: 90%;\n",
       "/*        margin-left:auto;*/\n",
       "/*        margin-right:auto;*/\n",
       "    }\n",
       "    ul {\n",
       "        line-height: 145%;\n",
       "        font-size: 90%;\n",
       "    }\n",
       "    li {\n",
       "        margin-bottom: 1em;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top: 12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        width: 90%;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Bayesian Computation\n",
    "\n",
    "The dominant issue in applying Bayesian methods to data analysis is the feasibility of calculating the posterior distribution. As we have seen, for most non-trivial problems, the posterior is analytically intractible. Computationally, it can be expensive to calculate or sample from.\n",
    "\n",
    "Approximation methods do exist, such as the Laplace approximation, but it relies on strong assumptions about the form of the posterior.\n",
    "\n",
    "Approximate Bayesian Computation (ABC) is a simulation-based approximation approach that avoids having to calculate the model likelihood, as we do for MCMC sampling. For this reason, it is sometimes called ***likelihood-free computation*** or ***likelihood-free MCMC***. Instead of evaluating the estimated posterior distribution at sampled values of the parameters, candidate parameters sample from their *prior* distribtions are used to generate simulated datasets; if the simulated data are deemed to be \"similar enough\" to the observed data, the proposed parameters are accepted. In this way, the data are thought to lend support to parameter values that might have generated them over those for which the observations would be less probable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood-free computation\n",
    "\n",
    "As is often the case in statistical computing, one effective strategy for improving compuational efficiency is to introduce auxilliary variables into a model. Such variables are solely for the purpose of facilitating computation, and play no role in inference.\n",
    "\n",
    "For approximate Bayesian computation, we do just this, augmenting the posterior with auxilliary data $x$:\n",
    "\n",
    "$$P(\\theta, x \\,|\\, y) \\propto P(y \\,|\\, \\theta, x) P(x \\,|\\, \\theta) P(\\theta)$$\n",
    "\n",
    "Upon inspection, we see that $x$ is drawn from a sampling distribution that is conditional on the prior of the parameter vector $\\theta$. Note also that since $x$ is sampled from the same parametric model as $y$, it occupies the same space as $y$.\n",
    "\n",
    "Ultimately, we want to integrate the auxilliary data from the posterior:\n",
    "\n",
    "$$P(\\theta \\,|\\, y) \\propto \\left[\\int P(y \\,|\\, \\theta, x) P(x \\,|\\, \\theta) dx\\right] P(\\theta)$$\n",
    "\n",
    "Of course, we are not able to perform this integration analytically. The thrust of ABC is that we integrate numerically by keeping samples from $P(\\theta)$ that generate sample which closely correspond to observed data (*i.e.* approximating the sampling process that generated $y$), and discarding the rest.\n",
    "\n",
    "Notice that when $x=y$, the augmented posterior becomes the posterior of interest:\n",
    "\n",
    "$$\\left[\\int P(y \\,|\\, \\theta, x=y) P(x=y \\,|\\, \\theta) dx\\right] P(\\theta) = P(y \\,|\\, \\theta) P(\\theta)$$\n",
    "\n",
    "Thus, a na√Øve form of ABC is to simulate from the prior, accepting only those parameters that result in simulated datasets that are exactly equivalent to the observed data $y$.\n",
    "\n",
    "This rejection algorithm is as follows:\n",
    "\n",
    "1. Sample parameters $\\theta^{(i)}$ from priors $P(\\theta)$.\n",
    "2. Simulate data $x^{(i)}$ from sampling distributions $x \\sim P(x \\,|\\, \\theta^{(i)})$.\n",
    "3. If $x^{(i)}==y$, keep $\\theta^{(i)}$ as sample from posterior.\n",
    "4. Repeat steps 1-3 until desired number of samples is obtained.\n",
    "\n",
    "Of course, for continuous variables, the sampled data will never be exactly equal to the observed data, and even for discrete variables sampling will be painfully inefficient. In order for ABC to be effective, we have to relax the check for equality, and accept samples that are merely \"close enough\" to the observed data. \n",
    "\n",
    "This simple change involves making two important choices: (1) deciding how to measure \"closeness\" and (2) deciding how close is \"close enough\"? In general, however, we can specify some function $\\rho(a, b)$ that returns some distance measure between $a$ and $b$, and compare this output to a chosen threshold value $\\epsilon$. With these changes, the ABC rejection algorithm becomes:\n",
    "\n",
    "1. Sample parameters $\\theta^{(i)}$ from priors $P(\\theta)$.\n",
    "2. Simulate data $x^{(i)}$ from sampling distributions $x \\sim P(x \\,|\\, \\theta^{(i)})$.\n",
    "3. If $\\rho(x, y) < \\epsilon$, keep $\\theta^{(i)}$ as sample from posterior.\n",
    "4. Repeat steps 1-3 until desired number of samples is obtained.\n",
    "\n",
    "A popular choice of distance measure is the Euclidean distance, which is provided in NumPy as `np.linalg.norm`. \n",
    "\n",
    "$$||x - y|| = \\sqrt{(x_1-y_1)^2 + \\ldots + (x_n-y_n)^2}< \\epsilon$$\n",
    "\n",
    "The quality of the approximation of the posterior depends on the choice of the tolerance $\\epsilon$. When $\\epsilon$ is too small, sampling will be inefficient; when $\\epsilon$ is too large, estimates will more strongly resemble the model priors. The convergence properties of ABC as a function of $\\epsilon$ are not clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics\n",
    "\n",
    "When data are of high (even moderate) dimension, comparing each datum in a simulated dataset with each corresponding datum in an observed dataset can result in low sampling efficiency; the probability of all simulated data simultaneously falling within the tolerance bound $\\epsilon$ of the observed data gets very small for a fixed $\\epsilon$ as the size of the dataset grows. Instead, *summary statistics* may be compared in order to keep the acceptance rate high.\n",
    "\n",
    "$$\\rho(T(x), T(y)) < \\epsilon$$\n",
    "\n",
    "For example, one might consider the mean, variance, autocorrelation, tail probabilities, *etc.* of the simulated and observed datasets. The use of summary statistics comes at a cost, however, since there is generally information loss upon summarization that results in estimation error. This compromise can be avoided if **sufficient statistics** are available, since sufficiency guarantees that all information about the posterior distribution is captured by that statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Fitting a Gaussian\n",
    "\n",
    "A very simple demonstration of ABC is to estimate the parameters of a particular statistical model. For example, let's simulate some data from a $N(4, 2)$ distibution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   2.,   5.,  11.,   8.,   9.,   9.,   2.,   3.]),\n",
       " array([-2.80186752, -1.67584599, -0.54982446,  0.57619707,  1.7022186 ,\n",
       "         2.82824013,  3.95426165,  5.08028318,  6.20630471,  7.33232624,\n",
       "         8.45834777]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEBCAYAAABlki5mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncoDmhBygOSEHaE7IAZr7P8YusDFaXAv6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11261ac90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "y = np.random.normal(4, 2, 50)\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up the ABC run, we first specify how many samples we want to draw from the posterior, as well as a tolerance for the distance measure to be used as the criterion for accepting or rejecting drawn values. Then, we need a data structure to store the accepted samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "epsilon = [0.2, 0.8]\n",
    "\n",
    "trace = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm then invloves repeatedly sampling from the priors on $\\mu$ and $\\sigma$, and using those draws to simulate some data. The mean and standard deviation of the simulations are compared to those for the observed data, and the corresponding parameter samples are stored if the distance is within the specified threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while len(trace) < N:\n",
    "    \n",
    "    # Simulate from priors\n",
    "    mu = np.random.normal(0, 10)\n",
    "    sigma = np.random.uniform(0, 20)\n",
    "    \n",
    "    x = np.random.normal(mu, sigma, 50)\n",
    "    \n",
    "    #if (np.linalg.norm(y - x) < epsilon):\n",
    "    if ((abs(x.mean() - y.mean()) < epsilon[0]) & \n",
    "        (abs(x.std() - y.std()) < epsilon[1])):\n",
    "        trace.append([mu, sigma])\n",
    "        \n",
    "trace = pd.DataFrame(trace, columns=['mu', 'sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEXCAYAAAD4LtBgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1126df950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trace.hist()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Coal mining disasters\n",
    "\n",
    "For a less trivial example, consider the following dataset, which is a time series of recorded coal mining disasters in the UK from 1851 to 1962 ([Jarrett 1979](http://www.jstor.org/stable/2335266)). Notice that the number of disasters each year appears to be lower in the later years than earlier.\n",
    "\n",
    "Annual counts of disasters in the dataset can be modeled as a Poisson process with a larger rate parameter early in the time series, and and a smaller rate in the later part. We are interested\n",
    "in locating the change point in the series, which perhaps is related to changes in mining safety regulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disasters_array = np.array([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,\n",
    "                         3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,\n",
    "                         2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3, 0, 0,\n",
    "                         1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,\n",
    "                         0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,\n",
    "                         3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,\n",
    "                         0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will compare the norms of the simulated and observed data, sorting them, since we are comparing based on the distribtion of the values, and not their order:\n",
    "\n",
    "    np.linalg.norm(np.sort(x_early) - np.sort(disasters_array[:switch]))\n",
    "    \n",
    "The priors for the Poisson means are sampled from an exponential distribution with mean 1, and the switch point from a discrete uniform over all the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6c2ce7ec6776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     if ((np.linalg.norm(np.sort(x_early) - np.sort(disasters_array[:switch])) < epsilon) & \n\u001b[0;32m---> 19\u001b[0;31m         (np.linalg.norm(np.sort(x_late) - np.sort(disasters_array[switch:])) < epsilon)):\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'switch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswitch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "epsilon = 2\n",
    "\n",
    "# Dict for holding accepted samples\n",
    "params = dict(switch=[], early_mean=[], late_mean=[])\n",
    "    \n",
    "while len(params['switch']) < N:\n",
    "        \n",
    "    # Simulate from priors\n",
    "    switch = np.random.randint(15, 90)\n",
    "    early_mean = np.random.exponential(1)\n",
    "    late_mean = np.random.exponential(1)\n",
    "    \n",
    "    # Simulate data\n",
    "    x_early = np.random.poisson(early_mean, switch)\n",
    "    x_late = np.random.poisson(late_mean, 111 - switch)\n",
    "    \n",
    "    if ((np.linalg.norm(np.sort(x_early) - np.sort(disasters_array[:switch])) < epsilon) & \n",
    "        (np.linalg.norm(np.sort(x_late) - np.sort(disasters_array[switch:])) < epsilon)):\n",
    "        \n",
    "        params['switch'].append(switch)\n",
    "        params['early_mean'].append(early_mean)\n",
    "        params['late_mean'].append(late_mean)\n",
    "\n",
    "trace = pd.DataFrame(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trace.hist(bins=np.sqrt(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison\n",
    "\n",
    "The approximate Bayesian computing approach can also be used for model selection, where several models are considered simultaneously. In addition to the parameters of each model, the inference considers the *model index* $M$, which is associated with its own prior distribution $P(m)$ $(m = 1,...,M)$, as well as a prior distribution on the parameters conditional on the value $m$ of the model index, $P_m(\\theta_m)$, defined on the parameter space $\\theta_m$. \n",
    "\n",
    "Discrimination among these models is then driven by the posterior distribution of $M$, a challenging computational target where ABC brings a straightforward solution. If $M$ is simply considered an additional parameter to be estimated, we can sample from its prior distribution just as with the model parameters.\n",
    "\n",
    "The algorithm is as follows:\n",
    "\n",
    "- Loop for N iterations:\n",
    "    - while $\\rho(T(x), T(y)) > \\epsilon$:\n",
    "        - sample $m$ from prior $P(m)$\n",
    "        - sample $\\theta_m$ from prior $P_m(\\theta_m)$\n",
    "        - simulate data x from model $f_m(x|\\theta_m)$\n",
    "    - set $m^{(i)} = m$ and $\\theta^{(i)} = \\theta_m$\n",
    "    \n",
    "As a contrived example, consider some data sampled from a *Gamma(10, 2)* distribution, where we are uncertain about the generating model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 200\n",
    "simdata = np.random.gamma(10,2,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.,  17.,  29.,  36.,  44.,  29.,  21.,   5.,   5.,  10.]),\n",
       " array([  5.99775652,   9.33886963,  12.67998274,  16.02109584,\n",
       "         19.36220895,  22.70332206,  26.04443516,  29.38554827,\n",
       "         32.72666138,  36.06777449,  39.40888759]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEBCAYAAACKUEVYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndhKrKcL3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1127ae310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(simdata, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might consider fitting a Gaussian distribution to this data, as an alternative to the Gamma. Thus, we can constuct an ABC model choice sampler for $M=2$ models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 500\n",
    "\n",
    "epsilon = [20, 10, 5]\n",
    "\n",
    "trace = dict(normal=[], gamma=[])\n",
    "\n",
    "def accept(x, simdata, e=epsilon):\n",
    "    \n",
    "    return ((abs(np.log(x.prod()) - np.log(simdata.prod())) < e[0]) & \n",
    "            (abs(x.sum() - simdata.sum()) < e[1]) &\n",
    "            (abs(x.std() - simdata.std()) < e[2]))\n",
    "    \n",
    "\n",
    "while (len(trace['normal']) + len(trace['gamma'])) < N:\n",
    "    \n",
    "    gamma = np.random.binomial(1, 0.5)\n",
    "    \n",
    "    if gamma:\n",
    "                \n",
    "        alpha, beta = np.random.exponential(10, 2)\n",
    "        \n",
    "        x = np.random.gamma(alpha, beta, n)\n",
    "        \n",
    "        if accept(x, simdata):\n",
    "            trace['gamma'].append([alpha, beta])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Simulate from priors\n",
    "        mu = np.random.normal(0, 10)\n",
    "        sigma = np.random.uniform(0, 20)\n",
    "        \n",
    "        x = np.random.normal(mu, sigma, n)\n",
    "            \n",
    "        if accept(x, simdata):\n",
    "            trace['normal'].append([mu, sigma])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[3.7685583930245818, 5.4865086739503042],\n",
       "  [8.3537029654537349, 2.5994968122333972],\n",
       "  [14.243896788191551, 1.498453827248629],\n",
       "  [7.2530666837074254, 2.9130769102288072],\n",
       "  [14.116535854471735, 1.4839523621734185],\n",
       "  [11.880099302944465, 1.7675869885600828],\n",
       "  [6.0702470137099969, 3.3412998164591374],\n",
       "  [11.198815277080168, 1.8620145374298049],\n",
       "  [37.529331906156223, 0.56371975558251675],\n",
       "  [26.483387823214155, 0.81323638931145581]],\n",
       " [[21.195591029887684, 5.61513457747637],\n",
       "  [20.30637140512448, 9.032891692124416],\n",
       "  [20.959194301822762, 7.017085381522938],\n",
       "  [21.23903534480616, 2.4985976611561855],\n",
       "  [21.470218654319755, 5.214749982021507],\n",
       "  [21.03472305909362, 3.296579649762319],\n",
       "  [21.038286545414483, 4.762632275554859],\n",
       "  [20.255379026353644, 8.603215918055959],\n",
       "  [21.743672763085012, 6.325931230981093],\n",
       "  [20.73668146261243, 3.402376632545965]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace['gamma'][:10], trace['normal'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ABC estimate of the posterior probability $P(m|y)$ is simply the acceptance frequency from model $m$:\n",
    "\n",
    "$$Pr(m) = \\frac{1}{N} \\sum_{i=1}^N I(m^{(i)}=m)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_gamma = len(trace['gamma'])/float(N)\n",
    "p_gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the posterior probabilities of models have been estimated, one can make full use of the techniques of Bayesian model comparison. For instance, to compare the relative plausibilities of two models $m=1$ and $m=2$, one can compute their posterior ratio, which is related to the Bayes factor $B_{1,2}$:\n",
    "\n",
    "$$\\frac{P(m=1|y)}{P(m=2|y)} = \\frac{P(y|m=1)P(m=1)}{P(y|m=2)P(m=2)} = B_{1,2}\\frac{P(m=1)}{P(m=2)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.311258278145695"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B12 = (p_gamma)/(1-p_gamma)\n",
    "B12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: ABC for bioassay analysis\n",
    "\n",
    "Implement an ABC scheme for estimating the parameters of the dose-response model for bioassay analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dose = np.array([-0.86, -0.3 , -0.05,  0.73])\n",
    "deaths = np.array([0, 1, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code your model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Sunn√•ker, M., Busetto, A. G., Numminen, E., Corander, J., Foll, M., & Dessimoz, C. (2013). Approximate Bayesian Computation. PLoS Computational Biology, 9(1), e1002803. [doi:10.1371/journal.pcbi.1002803](http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.1002803)\n",
    "\n",
    "Csill√©ry, K., Blum, M. G. B., Gaggiotti, O. E., & Fran√ßois, O. (2010). Approximate Bayesian Computation (ABC) in practice. Trends in Ecology & Evolution, 25(7), 410‚Äì418. [doi:10.1016/j.tree.2010.04.001](http://www.ncbi.nlm.nih.gov/pubmed/20488578)\n",
    "\n",
    "Marin, J.-M., Pudlo, P., Robert, C. P., & Ryder, R. J. (2011). Approximate Bayesian computational methods. Statistics and Computing, 22(6), 1167‚Äì1180. [doi:10.1007/s11222-011-9288-2](http://link.springer.com/content/pdf/10.1007%2Fs11222-011-9288-2.pdf)\n",
    "\n",
    "[The Rate of Convergence for Approximate Bayesian Computation](http://m.seehuhn.de/papers/ABC.pdf) by Stuart Barber, Jochen Voss and Mark Webster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
